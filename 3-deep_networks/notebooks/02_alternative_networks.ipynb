{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Other network shapes\n",
    "We saw networks with a single input and output. But sometimes you would want to have more then one input, or output. That can be done with the Functional API:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.insert(0, \"..\") \n",
    "from src.data import make_dataset\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "datafile = Path(\"..\") / \"data/processed/data.npy\"\n",
    "train, valid, test = make_dataset.load(datafile)\n",
    "X_train, y_train = train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "input1 = Input(shape=X_train.shape[1:])\n",
    "input2 = Input(shape=X_train.shape[1:])\n",
    "x1 = Dense(30, activation='relu')(input1)\n",
    "x2 = Dense(30, activation='relu')(input2)\n",
    "x = tf.concat([x1, x2], 1)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=[output])\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 30)           270         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           270         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_1 (TFOpLambda)        (None, 60)           0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            61          tf.concat_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we created two inputs, each going into their own, separate `Dense(30)` layer. Each of those outputs a vector of length 30. Note how we have to take care not to overwrite them. So we use `x1` and `x2`. The outputs are concatenated into a vector of lengthe 60, and fed into a `Dense(1)` layer. Let's say we want to output the x layer in an earlier stage, that can be done like this:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "input1 = Input(shape=X_train.shape[1:])\n",
    "input2 = Input(shape=X_train.shape[1:])\n",
    "x1 = Dense(30, activation='relu')(input1)\n",
    "x2 = Dense(30, activation='relu')(input2)\n",
    "x = tf.concat([x1, x2], 1)\n",
    "early_output = Dense(1)(x)\n",
    "x = Dense(30, activation='relu')(x)\n",
    "x = Dense(30, activation='relu')(x)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=[output, early_output])\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 30)           270         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 30)           270         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_2 (TFOpLambda)        (None, 60)           0           dense_8[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 30)           1830        tf.concat_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 30)           930         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            31          dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            61          tf.concat_2[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,392\n",
      "Trainable params: 3,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note, that Tensorflow will use the same loss function for both outputs.  If you dont want that, you will need to specify multiple losses, and if you don't want the losses to be added, you should add weights too.\n",
    "\n",
    "Also note, how we can reuse the variable `x` after we no longer have two datastreams we want to keep separate."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model.compile(loss=['mape', 'mse'], loss_weights=[0.9, 0.1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, these are already fairly complex models. Usually, you don't need to make things this complex. I just want you to know that you can do it like this, if you ever have the need to do so."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example, the `output` has a `mape` loss, the `early_output` an `mse` loss. The first one is weighted 0.9, the second one 0.1."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db087170558c29b52dbaae76c50e592938ff5c7e322e5472320136db97c05a97"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('deep1': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}