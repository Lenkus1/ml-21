{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Intro into tensorflow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from ray import tune\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.insert(0, \"..\") \n",
    "from src.data import make_dataset\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter tuning\n",
    "While it is really usefull to play with different architectures to see what happens, it can easily become very time consuming. Right now, we are just considering Dense layers, but we can add all sorts of layers in different combinations. The search-space is also much too big for a naive, brute force gridsearch. Especially if we are going to add in more types of layers, each with their own parameters.\n",
    "\n",
    "To do this more intelligent, we will use ~~kerastuner~~ raytuner. Ray is\n",
    "excellent for parallel computing, and works with any framework (tensorflow,\n",
    "pytorch, etc). \n",
    "\n",
    "This implements smart ways to sample the hyperparameter space. To do\n",
    "this, we will have to define a more generic model, the hypermodel.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will define ranges of hyperparameters. The input of our hypermodel will be\n",
    "the hyperparameters (`config`) later on. \n",
    "There are different types of hyperparameters: `Int`, `Float`, uniform\n",
    "distributions, normal distributions, etc. All the different types can be find in\n",
    "the [ray documentation](https://docs.ray.io/en/master/tune/api_docs/search_space.html#tune-sample-docs).\n",
    "\n",
    "First, we set the range of the amount of units in every dense layer to somewhere between 32 an 96, in steps of 32.\n",
    "Second, we add a for loop to add multiple dense layers, somewhere between 2 and 5 additional layers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "datafile = Path(\"..\") / \"data/processed/data.npy\"\n",
    "local_dir = Path(\"../models/ray\")\n",
    "logbase = Path(\"..\") / \"logs\"\n",
    "datafile.exists()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "config = {\n",
    "    \"datafile\" : datafile.absolute(),\n",
    "    \"units\" : tune.qrandint(16, 128, 8),\n",
    "    \"dense_layers\" : tune.randint(2,6), \n",
    "    \"activation\" : \"relu\", \n",
    "    \"optimizer\" : \"Adam\", \n",
    "    \"epochs\" : 100,\n",
    "    \"local_dir\" : local_dir.absolute(),\n",
    "    \"log_dir\" : logbase.absolute() / \"hypertuned\",\n",
    "    \"samples\" : 10,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The [hyperband algorithm](https://jmlr.org/papers/v18/16-558.html) (image (b), configuration evaluation) often outperforms bayesian search (image (a), Configuration selection), at least in speed. \n",
    "\n",
    "<img src=https://miro.medium.com/max/1400/1*DASrFL5AZNm2YjvJEq8z8w.png width=600/>\n",
    "\n",
    "However, according to the [No Free Lunch Theorem](https://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf) \"for any algorithm, any elevated performance over one class of problems is offset by performance over another class\". So, as a rule of thumb, use Hyperband, but there is no guarantee that you get the best results. We set the max_epochs low, to speed things up. We might get better results by increasing that number some, but for this tutorial it will take too long. And we can still get an improvement over what we had."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "analysis.best_config"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-17 12:33:04,942\tWARNING experiment_analysis.py:644 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from src.models import hypermodel\n",
    "model = hypermodel.hypermodel(analysis.best_config)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'src.models.hypermodel.hypermodel'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from src.models import train_model\n",
    "\n",
    "analysis = train_model.hypertune(iterations=50, config=config)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using AsyncHyperBand: num_stopped=9\n",
       "Bracket: Iter 80.000: None | Iter 20.000: -0.2765508145093918 | Iter 5.000: -0.3212141841650009<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.25 GiB heap, 0.0/2.13 GiB objects (0.0/4.0 CPU_group_0_ceacbd1a4b301da7fc5a5dabe5cd60ff, 0.0/4.0 CPU_group_295b68772dd3c2fec89c23e39e95fe1d, 0.0/4.0 CPU_group_0_295b68772dd3c2fec89c23e39e95fe1d, 0.0/4.0 CPU_group_ceacbd1a4b301da7fc5a5dabe5cd60ff)<br>Current best trial: b1e68_00001 with val_loss=0.2863180339336395 and parameters={'datafile': PosixPath('/Users/rgrouls/Documents/academy/HU/ml-21/deep1/notebooks/../data/processed/data.npy'), 'units': 72, 'dense_layers': 4, 'activation': 'relu', 'optimizer': 'Adam', 'epochs': 100, 'local_dir': PosixPath('/Users/rgrouls/Documents/academy/HU/ml-21/deep1/notebooks/../models/ray'), 'log_dir': PosixPath('/Users/rgrouls/Documents/academy/HU/ml-21/deep1/notebooks/../logs/hypertuned'), 'samples': 10}<br>Result logdir: /Users/rgrouls/Documents/academy/HU/ml-21/deep1/models/ray/hypertune<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  dense_layers</th><th style=\"text-align: right;\">  units</th><th style=\"text-align: right;\">    acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_hypermodel_b1e68_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">             3</td><td style=\"text-align: right;\">    120</td><td style=\"text-align: right;\">21.2207</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         3.66938</td><td style=\"text-align: right;\">  0.324065</td></tr>\n",
       "<tr><td>train_hypermodel_b1e68_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">             4</td><td style=\"text-align: right;\">     72</td><td style=\"text-align: right;\">15.3755</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        25.689  </td><td style=\"text-align: right;\">  0.286318</td></tr>\n",
       "<tr><td>train_hypermodel_b1e68_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">             2</td><td style=\"text-align: right;\">     40</td><td style=\"text-align: right;\">23.0022</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         3.08078</td><td style=\"text-align: right;\">  0.334201</td></tr>\n",
       "<tr><td>train_hypermodel_b1e68_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">             3</td><td style=\"text-align: right;\">    112</td><td style=\"text-align: right;\">21.0996</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         3.78572</td><td style=\"text-align: right;\">  0.389697</td></tr>\n",
       "<tr><td>train_hypermodel_b1e68_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">             5</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">22.773 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         3.56109</td><td style=\"text-align: right;\">  0.329557</td></tr>\n",
       "<tr><td>train_hypermodel_b1e68_00005</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">             3</td><td style=\"text-align: right;\">    120</td><td style=\"text-align: right;\">20.93  </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         3.46426</td><td style=\"text-align: right;\">  0.38555 </td></tr>\n",
       "<tr><td>train_hypermodel_b1e68_00006</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">             2</td><td style=\"text-align: right;\">     88</td><td style=\"text-align: right;\">21.6973</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         2.98837</td><td style=\"text-align: right;\">  0.569156</td></tr>\n",
       "<tr><td>train_hypermodel_b1e68_00007</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">             3</td><td style=\"text-align: right;\">     80</td><td style=\"text-align: right;\">18.296 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        10.2908 </td><td style=\"text-align: right;\">  0.291879</td></tr>\n",
       "<tr><td>train_hypermodel_b1e68_00008</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">             4</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">22.2392</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         3.38107</td><td style=\"text-align: right;\">  0.320264</td></tr>\n",
       "<tr><td>train_hypermodel_b1e68_00009</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">             3</td><td style=\"text-align: right;\">     88</td><td style=\"text-align: right;\">21.3543</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         2.67309</td><td style=\"text-align: right;\">  0.477528</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-17 12:35:21,426\tINFO tune.py:550 -- Total run time: 55.19 seconds (55.07 seconds for the tuning loop).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best hyperparameters found were:  {'datafile': PosixPath('/Users/rgrouls/Documents/academy/HU/ml-21/deep1/notebooks/../data/processed/data.npy'), 'units': 72, 'dense_layers': 4, 'activation': 'relu', 'optimizer': 'Adam', 'epochs': 100, 'local_dir': PosixPath('/Users/rgrouls/Documents/academy/HU/ml-21/deep1/notebooks/../models/ray'), 'log_dir': PosixPath('/Users/rgrouls/Documents/academy/HU/ml-21/deep1/notebooks/../logs/hypertuned'), 'samples': 10}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the CPU time is pretty fast for checking 10 configurations! As you can\n",
    "see, a lot of the models are aborted before the full training ends. We can obtain the best values from the search:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "analysis.best_config"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'datafile': PosixPath('/Users/rgrouls/Documents/academy/HU/ml-21/deep1/notebooks/../data/processed/data.npy'),\n",
       " 'units': 72,\n",
       " 'dense_layers': 4,\n",
       " 'activation': 'relu',\n",
       " 'optimizer': 'Adam',\n",
       " 'epochs': 100,\n",
       " 'local_dir': PosixPath('/Users/rgrouls/Documents/academy/HU/ml-21/deep1/notebooks/../models/ray'),\n",
       " 'log_dir': PosixPath('/Users/rgrouls/Documents/academy/HU/ml-21/deep1/notebooks/../logs/hypertuned'),\n",
       " 'samples': 10}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And use those to train a model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_model.train_hypermodel(analysis.best_config, verbose=1, tuning=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.6589 - mape: 32.5088 - val_loss: 0.6619 - val_mape: 24.6577\n",
      "Epoch 2/100\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3590 - mape: 24.1679 - val_loss: 0.4032 - val_mape: 24.4314\n",
      "Epoch 3/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3384 - mape: 23.0620 - val_loss: 0.3725 - val_mape: 20.4954\n",
      "Epoch 4/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3222 - mape: 22.1923 - val_loss: 0.6114 - val_mape: 27.4569\n",
      "Epoch 5/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3144 - mape: 21.5789 - val_loss: 0.4508 - val_mape: 23.3878\n",
      "Epoch 6/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2970 - mape: 20.8900 - val_loss: 0.3265 - val_mape: 19.3924\n",
      "Epoch 7/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2910 - mape: 20.4651 - val_loss: 0.3573 - val_mape: 19.1528\n",
      "Epoch 8/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2826 - mape: 20.1066 - val_loss: 0.4887 - val_mape: 20.9843\n",
      "Epoch 9/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2765 - mape: 19.9120 - val_loss: 0.2998 - val_mape: 20.2398\n",
      "Epoch 10/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2758 - mape: 19.7616 - val_loss: 0.3078 - val_mape: 19.4301\n",
      "Epoch 11/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2697 - mape: 19.5514 - val_loss: 0.3467 - val_mape: 19.0379\n",
      "Epoch 12/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2642 - mape: 19.1881 - val_loss: 0.2836 - val_mape: 18.5575\n",
      "Epoch 13/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2640 - mape: 19.2357 - val_loss: 0.3564 - val_mape: 20.0472\n",
      "Epoch 14/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2578 - mape: 18.8694 - val_loss: 0.2813 - val_mape: 19.7104\n",
      "Epoch 15/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2566 - mape: 18.8655 - val_loss: 0.2737 - val_mape: 19.7281\n",
      "Epoch 16/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2537 - mape: 18.6710 - val_loss: 0.3062 - val_mape: 20.7160\n",
      "Epoch 17/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2530 - mape: 18.7117 - val_loss: 0.2748 - val_mape: 20.7029\n",
      "Epoch 18/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2460 - mape: 18.5137 - val_loss: 0.3352 - val_mape: 19.2980\n",
      "Epoch 19/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.2447 - mape: 18.3884 - val_loss: 0.2937 - val_mape: 20.3410\n",
      "Epoch 20/100\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.2397 - mape: 17.9827 - val_loss: 0.2768 - val_mape: 19.9574\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Why not start with hypertuning directly? Because we first need to have an idea of where to search. Sure, you could start with an immmense parameter space and search that, but the chance of finding a good model will drop with the amount of space you need to search, even if you are using a smart way to search. Looking for a pebble will by much harder in the mountains and much easier in your backyard."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db087170558c29b52dbaae76c50e592938ff5c7e322e5472320136db97c05a97"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('deep1': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}